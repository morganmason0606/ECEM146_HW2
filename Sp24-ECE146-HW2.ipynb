{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "40nOq82Ha1zB"
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e_NuDNh9rUos"
   },
   "outputs": [],
   "source": [
    "# To add your own Drive Run this cell.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RWPBfJLfrkhJ"
   },
   "outputs": [],
   "source": [
    "# Please append your own directory after â€˜/content/drive/My Drive/'\n",
    "# where you have nutil.py and adult_subsample.csv\n",
    "### ========== TODO : START ========== ###\n",
    "# for example: sys.path += ['/content/drive/My Drive/cs146/hw2'] \n",
    "### ========== TODO : END ========== ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yxKg7xF1r82H"
   },
   "outputs": [],
   "source": [
    "from nutil import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "55EocyDPsWIb"
   },
   "outputs": [],
   "source": [
    "# Use only the provided packages!\n",
    "import math\n",
    "import csv\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dxpkWVRetDgo"
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Immutatble classes\n",
    "######################################################################\n",
    "\n",
    "class Classifier(object) :\n",
    "    \"\"\"\n",
    "    Classifier interface.\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def predict(self, X):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class MajorityVoteClassifier(Classifier) :\n",
    "\n",
    "    def __init__(self) :\n",
    "        \"\"\"\n",
    "        A classifier that always predicts the majority class.\n",
    "\n",
    "        Attributes\n",
    "        --------------------\n",
    "            prediction_ -- majority class\n",
    "        \"\"\"\n",
    "        self.prediction_ = None\n",
    "\n",
    "    def fit(self, X, y) :\n",
    "        \"\"\"\n",
    "        Build a majority vote classifier from the training set (X, y).\n",
    "\n",
    "        Parameters\n",
    "        --------------------\n",
    "            X    -- numpy array of shape (n,d), samples\n",
    "            y    -- numpy array of shape (n,), target classes\n",
    "\n",
    "        Returns\n",
    "        --------------------\n",
    "            self -- an instance of self\n",
    "        \"\"\"\n",
    "        majority_val = Counter(y).most_common(1)[0][0]\n",
    "        self.prediction_ = majority_val\n",
    "        return self\n",
    "\n",
    "    def predict(self, X) :\n",
    "        \"\"\"\n",
    "        Predict class values.\n",
    "\n",
    "        Parameters\n",
    "        --------------------\n",
    "            X    -- numpy array of shape (n,d), samples\n",
    "\n",
    "        Returns\n",
    "        --------------------\n",
    "            y    -- numpy array of shape (n,), predicted classes\n",
    "        \"\"\"\n",
    "        if self.prediction_ is None :\n",
    "            raise Exception(\"Classifier not initialized. Perform a fit first.\")\n",
    "\n",
    "        n,d = X.shape\n",
    "        y = [self.prediction_] * n\n",
    "        return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yefbwe8EvH-V"
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Mutatble classes\n",
    "######################################################################\n",
    "\n",
    "class RandomClassifier(Classifier) :\n",
    "\n",
    "    def __init__(self) :\n",
    "        \"\"\"\n",
    "        A classifier that predicts according to the distribution of the classes.\n",
    "\n",
    "        Attributes\n",
    "        --------------------\n",
    "            probabilities_ -- class distribution dict (key = class, val = probability of class)\n",
    "        \"\"\"\n",
    "        self.probabilities_ = None\n",
    "\n",
    "    def fit(self, X, y) :\n",
    "        \"\"\"\n",
    "        Build a random classifier from the training set (X, y).\n",
    "\n",
    "        Parameters\n",
    "        --------------------\n",
    "            X    -- numpy array of shape (n,d), samples\n",
    "            y    -- numpy array of shape (n,), target classes\n",
    "\n",
    "        Returns\n",
    "        --------------------\n",
    "            self -- an instance of self\n",
    "        \"\"\"\n",
    "\n",
    "        ### ========== TODO : START ========== ###\n",
    "        # part b: set self.probabilities_ according to the training set\n",
    "        pass\n",
    "\n",
    "        ### ========== TODO : END ========== ###\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, seed=1234) :\n",
    "        \"\"\"\n",
    "        Predict class values.\n",
    "\n",
    "        Parameters\n",
    "        --------------------\n",
    "            X    -- numpy array of shape (n,d), samples\n",
    "            seed -- integer, random seed\n",
    "\n",
    "        Returns\n",
    "        --------------------\n",
    "            y    -- numpy array of shape (n,), predicted classes\n",
    "        \"\"\"\n",
    "        if self.probabilities_ is None :\n",
    "            raise Exception(\"Classifier not initialized. Perform a fit first.\")\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        ### ========== TODO : START ========== ###\n",
    "        # part b: predict the class for each test example\n",
    "        # hint: use np.random.choice (be careful of the parameters)\n",
    "        pass\n",
    "        \n",
    "        ### ========== TODO : END ========== ###\n",
    "\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7m9qVosFwbAK"
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Immutatble functions\n",
    "######################################################################\n",
    "\n",
    "def plot_histograms(X, y, Xnames, yname) :\n",
    "    n,d = X.shape  # n = number of examples, d =  number of features\n",
    "    fig = plt.figure(figsize=(20,15))\n",
    "    ncol = 3\n",
    "    nrow = d // ncol + 1\n",
    "    for i in range(d) :\n",
    "        fig.add_subplot (nrow,ncol,i+1)\n",
    "        data, bins, align, labels = plot_histogram(X[:,i], y, Xname=Xnames[i], yname=yname, show = False)\n",
    "        n, bins, patches = plt.hist(data, bins=bins, align=align, alpha=0.5, label=labels)\n",
    "        plt.xlabel(Xnames[i])\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend() #plt.legend(loc='upper left')\n",
    "\n",
    "    plt.savefig ('histograms.pdf')\n",
    "\n",
    "\n",
    "def plot_histogram(X, y, Xname, yname, show = True) :\n",
    "    \"\"\"\n",
    "    Plots histogram of values in X grouped by y.\n",
    "\n",
    "    Parameters\n",
    "    --------------------\n",
    "        X     -- numpy array of shape (n,d), feature values\n",
    "        y     -- numpy array of shape (n,), target classes\n",
    "        Xname -- string, name of feature\n",
    "        yname -- string, name of target\n",
    "    \"\"\"\n",
    "\n",
    "    # set up data for plotting\n",
    "    targets = sorted(set(y))\n",
    "    data = []; labels = []\n",
    "    for target in targets :\n",
    "        features = [X[i] for i in range(len(y)) if y[i] == target]\n",
    "        data.append(features)\n",
    "        labels.append('%s = %s' % (yname, target))\n",
    "\n",
    "    # set up histogram bins\n",
    "    features = set(X)\n",
    "    nfeatures = len(features)\n",
    "    test_range = list(range(int(math.floor(min(features))), int(math.ceil(max(features)))+1))\n",
    "    if nfeatures < 10 and sorted(features) == test_range:\n",
    "        bins = test_range + [test_range[-1] + 1] # add last bin\n",
    "        align = 'left'\n",
    "    else :\n",
    "        bins = 10\n",
    "        align = 'mid'\n",
    "\n",
    "    # plot\n",
    "    if show == True:\n",
    "        plt.figure()\n",
    "        n, bins, patches = plt.hist(data, bins=bins, align=align, alpha=0.5, label=labels)\n",
    "        plt.xlabel(Xname)\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend() #plt.legend(loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "    return data, bins, align, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Z8oJrMgxc4_"
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Mutatble functions\n",
    "######################################################################\n",
    "\n",
    "def error(clf, X, y, ntrials=100, test_size=0.2) :\n",
    "    \"\"\"\n",
    "    Computes the classifier error over a random split of the data,\n",
    "    averaged over ntrials runs.\n",
    "\n",
    "    Parameters\n",
    "    --------------------\n",
    "        clf         -- classifier\n",
    "        X           -- numpy array of shape (n,d), features values\n",
    "        y           -- numpy array of shape (n,), target classes\n",
    "        ntrials     -- integer, number of trials\n",
    "\n",
    "    Returns\n",
    "    --------------------\n",
    "        train_error -- float, training error\n",
    "        test_error  -- float, test error\n",
    "        f1_score    -- float, test \"micro\" averaged f1 score\n",
    "    \"\"\"\n",
    "\n",
    "    ### ========== TODO : START ========== ###\n",
    "    # part e:\n",
    "    # compute cross-validation error using StratifiedShuffleSplit over ntrials\n",
    "    # hint: use StratifiedShuffleSplit (be careful of the parameters)\n",
    "    pass\n",
    "    ### ========== TODO : END ========== ###\n",
    "\n",
    "    return train_error, test_error, f1_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kRkKf8DUxMdX"
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# Immutatble functions\n",
    "######################################################################\n",
    "\n",
    "\n",
    "def write_predictions(y_pred, filename, yname=None) :\n",
    "    \"\"\"Write out predictions to csv file.\"\"\"\n",
    "    out = open(filename, 'wb')\n",
    "    f = csv.writer(out)\n",
    "    if yname :\n",
    "        f.writerow([yname])\n",
    "    f.writerows(list(zip(y_pred)))\n",
    "    out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_S9FqmRZPU9E"
   },
   "outputs": [],
   "source": [
    "######################################################################\n",
    "# main\n",
    "######################################################################\n",
    "    \n",
    "# load adult_subsample dataset with correct file path\n",
    "\n",
    "### ========== TODO : START ========== ###\n",
    "# for example data_file =  \"/content/drive/My Drive/cs146/hw1/adult_subsample.csv\"\n",
    "data_file = \"\"\n",
    "### ========== TODO : END ========== ###\n",
    "\n",
    "data = load_data(data_file, header=1, predict_col=-1)\n",
    "\n",
    "X = data.X; Xnames = data.Xnames\n",
    "y = data.y; yname = data.yname\n",
    "n,d = X.shape  # n = number of examples, d =  number of features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1LC8-rALPfrf"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "#========================================\n",
    "# part a: plot histograms of each feature\n",
    "print('Plotting...')\n",
    "plot_histograms (X, y, Xnames=Xnames, yname=yname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PaIjzhhAPraq"
   },
   "outputs": [],
   "source": [
    "#========================================\n",
    "# train Majority Vote classifier on data\n",
    "print('Classifying using Majority Vote...')\n",
    "clf = MajorityVoteClassifier() # create MajorityVote classifier, which includes all model parameters\n",
    "clf.fit(X, y)                  # fit training data using the classifier\n",
    "y_pred = clf.predict(X)        # take the classifier and run it on the training data\n",
    "train_error = 1 - metrics.accuracy_score(y, y_pred, normalize=True)\n",
    "print('\\t-- training error: %.3f' % train_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VY7fDwhUPv7i"
   },
   "outputs": [],
   "source": [
    "### ========== TODO : START ========== ###\n",
    "# part b: evaluate training error of Random classifier\n",
    "\n",
    "### ========== TODO : END ========== ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PMQBfC0YQtUc"
   },
   "outputs": [],
   "source": [
    "### ========== TODO : START ========== ###\n",
    "# part c: evaluate training error of Decision Tree classifier\n",
    "\n",
    "### ========== TODO : END ========== ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RWheEPUORT5Q"
   },
   "outputs": [],
   "source": [
    "### ========== TODO : START ========== ###\n",
    "# part d: evaluate training error of k-Nearest Neighbors classifier\n",
    "# use k = 3, 5, 7 for n_neighbors\n",
    "### ========== TODO : END ========== ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7dMk_vNqgtiU"
   },
   "outputs": [],
   "source": [
    "### ========== TODO : START ========== ###\n",
    "# part e: evaluate training error of Logistic Regression\n",
    "# use lambda_ = 0.1, 1, 10 for n_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 135,
     "status": "ok",
     "timestamp": 1682214057125,
     "user": {
      "displayName": "MEIHUA DANG",
      "userId": "02500643429334115338"
     },
     "user_tz": 420
    },
    "id": "wW5YY7QdTncR",
    "outputId": "295c17a5-a0f3-402a-e3b5-41b6b6c7bf04"
   },
   "outputs": [],
   "source": [
    "### ========== TODO : START ========== ###\n",
    "# part f: use cross-validation to compute average training and test error of classifiers\n",
    "print('Investigating various classifiers...')\n",
    "### ========== TODO : END ========== ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1682214063425,
     "user": {
      "displayName": "MEIHUA DANG",
      "userId": "02500643429334115338"
     },
     "user_tz": 420
    },
    "id": "-tUQeb4rUv_y",
    "outputId": "ea1a4f0b-373e-49e7-c323-f18cca0f057e"
   },
   "outputs": [],
   "source": [
    "### ========== TODO : START ========== ###\n",
    "# part g: use 5-fold cross-validation to find the best value of k for k-Nearest Neighbors classifier\n",
    "print('Finding the best k...')\n",
    "\n",
    "### ========== TODO : END ========== ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 134,
     "status": "ok",
     "timestamp": 1682214068732,
     "user": {
      "displayName": "MEIHUA DANG",
      "userId": "02500643429334115338"
     },
     "user_tz": 420
    },
    "id": "-kbElhW9XN0R",
    "outputId": "69f0fb56-0cec-45b3-ec9c-227f4fa34357"
   },
   "outputs": [],
   "source": [
    "### ========== TODO : START ========== ###\n",
    "# part h: investigate decision tree classifier with various depths\n",
    "print('Investigating depths...')\n",
    "\n",
    "### ========== TODO : END ========== ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 130,
     "status": "ok",
     "timestamp": 1682214949132,
     "user": {
      "displayName": "MEIHUA DANG",
      "userId": "02500643429334115338"
     },
     "user_tz": 420
    },
    "id": "_HdZPr0TsvYV",
    "outputId": "10f44c75-d243-47fd-8cb4-675a5dde6c63"
   },
   "outputs": [],
   "source": [
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1YXJ7a6JOPjP80Jt86D2eJWqwjNIa2gdi",
     "timestamp": 1682213332894
    },
    {
     "file_id": "1_O5QwkZ33fnYbW3zwSnKjeVYkeoEtIeD",
     "timestamp": 1635051123661
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
